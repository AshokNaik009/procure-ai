# Procurement Intelligence System ğŸ¤–

An AI-powered procurement intelligence platform that combines **LangGraph agent workflows** with real-time supplier discovery and market analysis.

## ğŸ¯ **Core Features**

- **ğŸ¤– LangGraph Agent Workflow**: Structured 4-step AI procurement analysis
- **ğŸ” Real-time Supplier Discovery**: DuckDuckGo search with AI enhancement
- **ğŸ“Š Market Intelligence**: AI-powered market trends and pricing analysis
- **âš¡ Dual LLM Integration**: Groq and Gemini APIs with fallback support
- **ğŸ’¾ Smart Caching**: In-memory caching for improved performance
- **ğŸŒ Professional UI**: Clean, responsive web interface
- **ğŸš€ Zero-Config Deployment**: Ready for Render deployment

## ğŸ—ï¸ **LangGraph Agent Workflow**

```mermaid
graph TD
    A[ğŸ” Search Suppliers] --> B[ğŸ¤– Analyze Suppliers]
    B --> C[ğŸ“Š Generate Market Insights]
    C --> D[ğŸ“ Create Summary]
    
    A1[Multi-Query DuckDuckGo Search] --> A
    A2[Rate Limiting & Caching] --> A
    A3[Result Deduplication] --> A
    
    B1[Extract Company Info] --> B
    B2[LLM Enhancement] --> B
    B3[Confidence Scoring] --> B
    
    C1[Price Trend Analysis] --> C
    C2[Market Factor Identification] --> C
    C3[Procurement Recommendations] --> C
    
    D1[Executive Summary] --> D
    D2[Processing Metrics] --> D
    D3[Next Steps] --> D
    
    style A fill:#e1f5fe
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e8
```

## ğŸ“ **Simplified Architecture**

```
procure_project/
â”œâ”€â”€ main.py                 # FastAPI app with embedded HTML
â”œâ”€â”€ agent_graph.py          # LangGraph workflow definition
â”œâ”€â”€ search_service.py       # DuckDuckGo search service
â”œâ”€â”€ llm_service.py          # Groq + Gemini LLM service
â”œâ”€â”€ requirements.txt        # Minimal dependencies
â””â”€â”€ .env                    # API configuration
```

## ğŸš€ **Quick Start**

### **Prerequisites**
- Python 3.11+ (recommended)
- Groq API key
- Gemini API key

### **Installation**

```bash
# 1. Clone and navigate to project
git clone <repository-url>
cd procure_project

# 2. Create virtual environment with Python 3.11
python3.11 -m venv procurement_env
source procurement_env/bin/activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Configure environment variables
# Edit .env file with your API keys:
GROQ_API_KEY=your_groq_key
GEMINI_API_KEY=your_gemini_key

# 5. Run the application
python main.py
```

### **Access the Application**
- **Dashboard**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health

## ğŸ“Š **API Endpoints**

### **Main Analysis Endpoint**
```bash
POST /analyze
```

**Request:**
```json
{
  "query": "industrial steel suppliers",
  "location": "Texas",
  "category": "materials"
}
```

**Response:**
```json
{
  "suppliers": [
    {
      "name": "Steel Corp Inc",
      "location": "Houston, Texas",
      "confidence_score": 0.85,
      "certifications": ["ISO 9001", "AS9100"],
      "rating": 4.2,
      "website": "https://steelcorp.com"
    }
  ],
  "market_insights": {
    "price_trend": "increasing",
    "key_factors": ["Raw material costs", "Supply chain disruptions"],
    "recommendations": ["Consider bulk purchasing", "Negotiate long-term contracts"]
  },
  "summary": "Found 5 suppliers for 'industrial steel' in Texas. Market trend: increasing.",
  "processing_time": 3.2
}
```

### **Health Check**
```bash
GET /health
```

## ğŸ”§ **Dependencies**

**Core Dependencies:**
```txt
fastapi              # Modern web framework
uvicorn             # ASGI server
duckduckgo-search   # Search engine integration
groq                # Groq LLM API
google-generativeai # Gemini API
langgraph           # Agent workflow framework
langchain-core      # LangChain core components
pydantic            # Data validation
python-dotenv       # Environment management
```

## ğŸ¨ **Frontend Features**

- **ğŸ“± Responsive Design**: Mobile-first approach
- **ğŸ”„ Workflow Visualization**: Real-time LangGraph step tracking
- **ğŸ“Š Supplier Cards**: Confidence scores, certifications, ratings
- **ğŸ“ˆ Market Insights**: Price trends, key factors, recommendations
- **âš¡ Real-time Updates**: Progress tracking during analysis
- **ğŸ¯ Professional UI**: Clean, modern interface

## ğŸš€ **Deployment**

### **Render Web Service Deployment (Docker)**

#### **Step 1: Create Render Web Service**
1. Go to https://render.com/dashboard
2. Click "New" â†’ "Web Service"
3. Connect your GitHub repository: `https://github.com/AshokNaik009/procure-ai.git`

#### **Step 2: Configure Service**
```
Name: procure-ai
Environment: Docker
Branch: main
```

#### **Step 3: Docker Configuration**
Render will automatically detect your `Dockerfile` and use it for deployment.

#### **Step 4: Set Environment Variables**
```
GROQ_API_KEY=your_actual_groq_key
GEMINI_API_KEY=your_actual_gemini_key
```

#### **Step 5: Deploy**
- Click "Create Web Service"
- Wait 5-10 minutes for Docker build and deployment
- Your app will be live at: `https://procure-ai.onrender.com`

### **Why Docker for Render?**
- **Solves dependency issues**: Avoids Rust compilation problems
- **Consistent environment**: Same container locally and in production
- **Better performance**: Optimized Python runtime
- **Easier debugging**: Clear build process

### **Local Development**
```bash
# Development mode with auto-reload
uvicorn main:app --reload --host 0.0.0.0 --port 8000

# OR with Docker
docker build -t procure-ai .
docker run -p 8000:8000 --env-file .env procure-ai
```

## ğŸ” **Usage Examples**

### **Basic Supplier Search**
```bash
curl -X POST "http://localhost:8000/analyze" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "manufacturing equipment",
    "location": "California"
  }'
```

### **Category-Specific Search**
```bash
curl -X POST "http://localhost:8000/analyze" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "IT services",
    "category": "services",
    "location": "New York"
  }'
```

## ğŸ“ˆ **Performance Metrics**

- **âš¡ Response Time**: 3-5 seconds for complete analysis
- **ğŸ” Search Coverage**: Multi-angle supplier discovery
- **ğŸ¤– AI Accuracy**: 85%+ confidence scoring
- **ğŸ’¾ Cache Efficiency**: 30-minute result caching
- **ğŸš€ Concurrent Users**: Supports multiple simultaneous requests

## ğŸ”§ **Configuration**

### **Environment Variables**
```bash
# Required
GROQ_API_KEY=your_groq_key
GEMINI_API_KEY=your_gemini_key

# Optional
CACHE_TTL=1800              # Cache TTL in seconds
SEARCH_DELAY=1.0            # Rate limiting delay
MAX_RESULTS=10              # Maximum search results
```

### **Customization Options**
- **Search Providers**: Easily extensible to other search engines
- **LLM Models**: Configurable model selection
- **Caching Strategy**: Adjustable TTL and cache keys
- **UI Themes**: Customizable styling

## ğŸ”„ **LangGraph Workflow Details**

### **Step 1: Search Suppliers** ğŸ”
- Multi-query DuckDuckGo search strategy
- Location-based filtering
- Result deduplication and ranking
- Rate limiting and caching

### **Step 2: Analyze Suppliers** ğŸ¤–
- Extract company information
- LLM-powered data enhancement
- Confidence score calculation
- Certification extraction

### **Step 3: Generate Market Insights** ğŸ“Š
- Price trend analysis
- Market factor identification
- Competitive landscape assessment
- Procurement recommendations

### **Step 4: Create Summary** ğŸ“
- Executive summary generation
- Processing metrics
- Next steps recommendations
- Confidence assessment

## ğŸ› ï¸ **Development**

### **Project Structure**
```
â”œâ”€â”€ main.py                 # FastAPI application
â”œâ”€â”€ agent_graph.py          # LangGraph workflow
â”œâ”€â”€ search_service.py       # Search functionality
â”œâ”€â”€ llm_service.py          # LLM integration
â”œâ”€â”€ requirements.txt        # Dependencies
â””â”€â”€ .env                    # Configuration
```

### **Testing**
```bash
# Test the application
python -c "
import requests
response = requests.post('http://localhost:8000/analyze', 
                        json={'query': 'steel suppliers'})
print(response.json())
"
```

## ğŸ”® **Future Enhancements**

- **ğŸŒ Multi-Language Support**: International supplier discovery
- **ğŸ“Š Advanced Analytics**: Detailed market reporting
- **ğŸ”” Alert System**: Price change notifications
- **ğŸ“± Mobile App**: Native mobile experience
- **ğŸ¤ Integration APIs**: ERP system connections
- **ğŸ”’ Enterprise Features**: User management, audit trails

## ğŸ¤ **Contributing**

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“„ **License**

This project is licensed under the MIT License.

## ğŸ™ **Acknowledgments**

- **LangGraph**: For the agent workflow framework
- **DuckDuckGo**: For privacy-focused search
- **Groq & Gemini**: For LLM capabilities
- **FastAPI**: For the modern web framework

---

**Built with â¤ï¸ for intelligent procurement decisions**

## ğŸ†˜ **Support**

For issues and questions:
- **GitHub Issues**: Technical problems
- **Documentation**: Comprehensive inline docs
- **Examples**: Working code samples included